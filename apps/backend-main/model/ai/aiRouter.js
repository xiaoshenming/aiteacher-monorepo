// routes/ai.js
const express = require("express");
const router = express.Router();
const { getAIResponseStream, getAIResponse, getAIResponseStreamCustom } = require("./aiUtils");
const db = require("../../config/db");
const authorize = require("../auth/authUtils");
const { promisify } = require('util');
const query = promisify(db.query).bind(db);

// è®°å½•AIä½¿ç”¨ç»Ÿè®¡çš„è¾…åŠ©å‡½æ•°
async function recordAIUsage(userId, userType, modelName, functionName, tokenConsumed = 0) {
  try {
    console.log('[recordAIUsage] å¼€å§‹è®°å½•:', { userId, userType, modelName, functionName, tokenConsumed });
    const callDate = new Date().toISOString().split('T')[0];
    
    // æ£€æŸ¥ä»Šå¤©æ˜¯å¦å·²æœ‰è®°å½•
    const checkSql = `SELECT id, call_count, token_consumed FROM ai_usage_stats 
      WHERE user_id = ? AND model_name = ? AND function_name = ? AND call_date = ?`;
    const existing = await query(checkSql, [userId, modelName, functionName, callDate]);
    
    console.log('[recordAIUsage] æŸ¥è¯¢ç»“æžœ:', existing.length > 0 ? 'æœ‰è®°å½•ï¼Œæ›´æ–°' : 'æ— è®°å½•ï¼Œæ’å…¥');
    
    if (existing.length > 0) {
      // æ›´æ–°è®°å½•
      const updateSql = `UPDATE ai_usage_stats 
        SET call_count = call_count + 1, token_consumed = token_consumed + ?
        WHERE id = ?`;
      await query(updateSql, [tokenConsumed, existing[0].id]);
      console.log('[recordAIUsage] æ›´æ–°æˆåŠŸ, ID:', existing[0].id);
    } else {
      // æ’å…¥æ–°è®°å½•
      const insertSql = `INSERT INTO ai_usage_stats 
        (user_id, user_type, model_name, function_name, call_count, token_consumed, call_date) 
        VALUES (?, ?, ?, ?, 1, ?, ?)`;
      const result = await query(insertSql, [userId, userType, modelName, functionName, tokenConsumed, callDate]);
      console.log('[recordAIUsage] æ’å…¥æˆåŠŸ, ID:', result.insertId);
    }
  } catch (error) {
    console.error("[recordAIUsage] è®°å½•AIä½¿ç”¨ç»Ÿè®¡å¤±è´¥:", error);
    // ä¸é˜»å¡žä¸»æµç¨‹
  }
}

// æ™®é€š AI èŠå¤©æŽ¥å£
router.post("/chat", authorize(["0", "1", "2", "3", "4"]), async (req, res) => {
  const { prompt, model = "deepseek-chat" } = req.body;
  const userId = req.user?.id;
  const userType = req.user?.role || 'teacher';
  
  if (!prompt || typeof prompt !== "string") {
    return res.status(400).json({
      code: 400,
      message: "Prompt must be a non-empty string.",
      data: null,
    });
  }
  try {
    const aiResponse = await getAIResponse(prompt, model);
    
    // è®°å½•ä½¿ç”¨ç»Ÿè®¡ï¼ˆç®€å•ä¼°ç®—tokenï¼‰
    const estimatedTokens = Math.ceil((prompt.length + aiResponse.length) / 4);
    if (userId) {
      await recordAIUsage(userId, userType, model, 'ai_chat', estimatedTokens);
    }
    
    return res.json({
      code: 200,
      message: "AI response fetched successfully",
      data: { response: aiResponse },
    });
  } catch (error) {
    console.error("Error handling AI request:", error);
    return res.status(500).json({
      code: 500,
      message: "Error processing AI request",
      data: null,
    });
  }
});

// SSE æµå¼ AI èŠå¤©æŽ¥å£
router.post("/chat-stream", authorize(["0", "1", "2", "3", "4"]), async (req, res) => {
  const { prompt, model = "deepseek-chat" } = req.body;
  const userId = req.user?.id;
  const userType = req.user?.role || 'teacher';
  
  if (!prompt || typeof prompt !== "string") {
    return res.status(400).json({
      code: 400,
      message: "Prompt must be a non-empty string.",
      data: null,
    });
  }
  try {
    res.setHeader("Content-Type", "text/event-stream");
    res.setHeader("Cache-Control", "no-cache");
    res.setHeader("Connection", "keep-alive");

    const sendEvent = (data, event = "message") => {
      res.write(`event: ${event}\n`);
      res.write(`data: ${JSON.stringify(data)}\n\n`);
    };

    let fullResponse = '';
    await getAIResponseStream(prompt, (chunk) => {
      fullResponse += chunk;
      sendEvent({
        code: 200,
        message: "STREAMING",
        data: {
          chunk,
          done: false,
        },
      });
    }, model);

    sendEvent(
      {
        code: 200,
        message: "COMPLETED",
        data: {
          done: true,
        },
      },
      "done"
    );

    // è®°å½•ä½¿ç”¨ç»Ÿè®¡
    const estimatedTokens = Math.ceil((prompt.length + fullResponse.length) / 4);
    console.log('[AIç»Ÿè®¡] userId:', userId, 'userType:', userType, 'model:', model, 'tokens:', estimatedTokens);
    if (userId) {
      await recordAIUsage(userId, userType, model, 'ai_chat_stream', estimatedTokens);
      console.log('[AIç»Ÿè®¡] è®°å½•å®Œæˆ');
    } else {
      console.log('[AIç»Ÿè®¡] userIdä¸ºç©ºï¼Œè·³è¿‡è®°å½•');
    }

    res.end();
  } catch (error) {
    console.error("Error handling AI request:", error);
    res.write(`event: error\n`);
    res.write(
      `data: ${JSON.stringify({
        code: 500,
        message: "Error processing AI request",
        data: null,
      })}\n\n`
    );
    res.end();
  }
});

// ç”Ÿæˆä¼šè®®çºªè¦æŽ¥å£
router.post("/meeting-summary", authorize(["0", "1", "2", "3", "4"]), async (req, res) => {
  const { transcript, duration, model = "deepseek-chat" } = req.body;
  const userId = req.user?.id;
  const userType = req.user?.role || 'teacher';

  if (!transcript || typeof transcript !== "string" || transcript.trim().length === 0) {
    return res.status(400).json({
      code: 400,
      message: "Transcript must be a non-empty string.",
      data: null,
    });
  }

  try {
    // æž„å»ºä¼šè®®çºªè¦æç¤ºè¯
    const prompt = `è¯·æ ¹æ®ä»¥ä¸‹ä¼šè®®è½¬å½•å†…å®¹ç”Ÿæˆä¸€ä»½ç»“æž„åŒ–çš„ä¼šè®®çºªè¦ï¼š

ä¼šè®®æ—¶é•¿ï¼š${duration || 'æœªçŸ¥'}
è½¬å½•å†…å®¹ï¼š
${transcript}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆä¼šè®®çºªè¦ï¼š

## ðŸ“… ä¼šè®®æ¦‚è¦
- **æ—¶é—´ï¼š** [å½“å‰æ—¥æœŸæ—¶é—´]
- **æ—¶é•¿ï¼š** ${duration || 'æœªçŸ¥'}
- **å­—æ•°ï¼š** ${transcript.length} å­—

## ðŸ’¡ æ ¸å¿ƒè®®é¢˜
[æ€»ç»“ä¼šè®®è®¨è®ºçš„ä¸»è¦è®®é¢˜ï¼Œ2-3å¥è¯]

## ðŸ“ ä¸»è¦å†…å®¹
### è®¨è®ºè¦ç‚¹
- [è¦ç‚¹1]
- [è¦ç‚¹2]
- [è¦ç‚¹3]

### é‡è¦è§‚ç‚¹
- [è§‚ç‚¹1]
- [è§‚ç‚¹2]

## âœ… å¾…åŠžäº‹é¡¹ (Action Items)
1. [ ] [å…·ä½“å¾…åŠžäº‹é¡¹1] - [è´Ÿè´£äºº/æ—¶é—´]
2. [ ] [å…·ä½“å¾…åŠžäº‹é¡¹2] - [è´Ÿè´£äºº/æ—¶é—´]
3. [ ] [å…·ä½“å¾…åŠžäº‹é¡¹3] - [è´Ÿè´£äºº/æ—¶é—´]

## ðŸŽ¯ å†³ç­–ç»“è®º
- [å†³ç­–1]
- [å†³ç­–2]

## ðŸ“Œ å¤‡æ³¨
[å…¶ä»–éœ€è¦è®°å½•çš„é‡è¦ä¿¡æ¯]

è¯·ç¡®ä¿çºªè¦ç®€æ´æ˜Žäº†ï¼Œé‡ç‚¹çªå‡ºï¼Œä¾¿äºŽåŽç»­æŸ¥é˜…å’Œæ‰§è¡Œã€‚`;

    const aiResponse = await getAIResponse(prompt, model);

    // è®°å½•ä½¿ç”¨ç»Ÿè®¡ï¼ˆç®€å•ä¼°ç®—tokenï¼‰
    const estimatedTokens = Math.ceil((prompt.length + aiResponse.length) / 4);
    if (userId) {
      await recordAIUsage(userId, userType, model, 'meeting_summary', estimatedTokens);
    }

    return res.json({
      code: 200,
      message: "Meeting summary generated successfully",
      data: {
        summary: aiResponse,
        tokens: estimatedTokens,
        model: model
      },
    });
  } catch (error) {
    console.error("Error generating meeting summary:", error);
    return res.status(500).json({
      code: 500,
      message: "Error generating meeting summary",
      data: null,
    });
  }
});

// ç¿»è¯‘æŽ¥å£
router.post("/translate", authorize(["0", "1", "2", "3", "4"]), async (req, res) => {
  const { text, from = "auto", to = "en", model = "deepseek-chat" } = req.body;
  const userId = req.user?.id;
  const userType = req.user?.role || 'teacher';

  if (!text || typeof text !== "string" || text.trim().length === 0) {
    return res.status(400).json({
      code: 400,
      message: "Text must be a non-empty string.",
      data: null,
    });
  }

  try {
    // æž„å»ºç¿»è¯‘æç¤ºè¯
    const prompt = `è¯·å°†ä»¥ä¸‹${from === 'zh' ? 'ä¸­æ–‡' : from === 'en' ? 'è‹±æ–‡' : 'æ–‡æœ¬'}ç¿»è¯‘æˆ${to === 'zh' ? 'ä¸­æ–‡' : to === 'en' ? 'è‹±æ–‡' : to}ã€‚

è¦æ±‚ï¼š
1. ä¿æŒåŽŸæ–‡çš„è¯­æ°”å’Œé£Žæ ¼
2. ç¡®ä¿ç¿»è¯‘å‡†ç¡®ã€è‡ªç„¶ã€æµç•…
3. ä¸“æœ‰åè¯ä½¿ç”¨é€šç”¨ç¿»è¯‘
4. åªè¿”å›žç¿»è¯‘ç»“æžœï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Š

åŽŸæ–‡ï¼š
${text}

ç¿»è¯‘ï¼š`;

    const aiResponse = await getAIResponse(prompt, model);

    // è®°å½•ä½¿ç”¨ç»Ÿè®¡ï¼ˆç®€å•ä¼°ç®—tokenï¼‰
    const estimatedTokens = Math.ceil((prompt.length + aiResponse.length) / 4);
    if (userId) {
      await recordAIUsage(userId, userType, model, 'translate', estimatedTokens);
    }

    return res.json({
      code: 200,
      message: "Translation completed successfully",
      data: {
        translatedText: aiResponse,
        tokens: estimatedTokens,
        model: model
      },
    });
  } catch (error) {
    console.error("Error handling translation request:", error);
    return res.status(500).json({
      code: 500,
      message: "Error processing translation request",
      data: null,
    });
  }
});

// ç¼–è¾‘å™¨ AI å†…è”ç»­å†™æŽ¥å£ï¼ˆSSE æµå¼ï¼‰
router.post("/editor-completion", authorize(["0", "1", "2", "3", "4"]), async (req, res) => {
  const { prompt, model = "deepseek-chat" } = req.body;
  const userId = req.user?.id;
  const userType = req.user?.role || 'teacher';

  if (!prompt || typeof prompt !== "string") {
    return res.status(400).json({
      code: 400,
      message: "Prompt must be a non-empty string.",
      data: null,
    });
  }

  try {
    res.setHeader("Content-Type", "text/event-stream");
    res.setHeader("Cache-Control", "no-cache");
    res.setHeader("Connection", "keep-alive");
    res.setHeader("X-Accel-Buffering", "no");

    const sendEvent = (data, event = "message") => {
      res.write(`event: ${event}\n`);
      res.write(`data: ${JSON.stringify(data)}\n\n`);
    };

    const systemPrompt = `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•™è‚²å·¥ä½œè€…å’Œå†™ä½œåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·å·²æœ‰çš„æ•™æ¡ˆæˆ–æ–‡æ¡£å†…å®¹ï¼Œè‡ªç„¶åœ°ç»­å†™ä¸‹åŽ»ã€‚

è¦æ±‚ï¼š
1. ä¿æŒä¸Žå‰æ–‡ä¸€è‡´çš„è¯­æ°”ã€é£Žæ ¼å’Œæ ¼å¼
2. ç»­å†™å†…å®¹è¦è‡ªç„¶è¿žè´¯ï¼Œåƒæ˜¯åŒä¸€ä¸ªäººå†™çš„
3. åªè¾“å‡ºç»­å†™çš„å†…å®¹ï¼Œä¸è¦é‡å¤å‰æ–‡ï¼Œä¸è¦æ·»åŠ è§£é‡Š
4. ç»­å†™é•¿åº¦é€‚ä¸­ï¼ˆ1-3å¥è¯ï¼‰ï¼Œä¸è¦è¿‡é•¿
5. å¦‚æžœå‰æ–‡æ˜¯ Markdown æ ¼å¼ï¼Œç»­å†™ä¹Ÿä½¿ç”¨ Markdown
6. å†…å®¹è¦ä¸“ä¸šã€å‡†ç¡®ï¼Œé€‚åˆæ•™è‚²åœºæ™¯`;

    let fullResponse = '';
    await getAIResponseStreamCustom({
      prompt: prompt,
      systemPrompt: systemPrompt,
      callback: (chunk) => {
        fullResponse += chunk;
        sendEvent({
          code: 200,
          message: "STREAMING",
          data: {
            chunk,
            done: false,
          },
        });
      },
      model: model,
      maxTokens: 256
    });

    sendEvent(
      {
        code: 200,
        message: "COMPLETED",
        data: {
          done: true,
        },
      },
      "done"
    );

    // è®°å½•ä½¿ç”¨ç»Ÿè®¡
    const estimatedTokens = Math.ceil((prompt.length + fullResponse.length) / 4);
    if (userId) {
      await recordAIUsage(userId, userType, model, 'editor_completion', estimatedTokens);
    }

    res.end();
  } catch (error) {
    console.error("Error handling editor completion request:", error);
    res.write(`event: error\n`);
    res.write(
      `data: ${JSON.stringify({
        code: 500,
        message: "Error processing editor completion request",
        data: null,
      })}\n\n`
    );
    res.end();
  }
});

module.exports = router;
