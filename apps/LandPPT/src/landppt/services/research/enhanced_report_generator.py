"""
Enhanced Report Generator for Comprehensive Research Reports

This module provides flexible, detailed report generation without rigid module divisions,
focusing on comprehensive content analysis and professional presentation.
"""

import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from .enhanced_research_service import EnhancedResearchReport, EnhancedResearchStep

logger = logging.getLogger(__name__)


class EnhancedReportGenerator:
    """Generate comprehensive, flexible research reports"""
    
    def __init__(self, reports_dir: str = "research_reports"):
        self.reports_dir = Path(reports_dir)
        self.reports_dir.mkdir(exist_ok=True)
        logger.info(f"Enhanced research reports directory: {self.reports_dir.absolute()}")
    
    def generate_markdown_report(self, report: EnhancedResearchReport) -> str:
        """Generate comprehensive Markdown formatted research report"""
        
        # Build comprehensive report content
        markdown_content = self._build_enhanced_markdown_content(report)
        return markdown_content
    
    def save_report_to_file(self, report: EnhancedResearchReport, 
                          custom_filename: Optional[str] = None) -> str:
        """Save enhanced research report to file"""
        
        try:
            # Generate filename
            if custom_filename:
                filename = custom_filename
                if not filename.endswith('.md'):
                    filename += '.md'
            else:
                safe_topic = self._sanitize_filename(report.topic)
                timestamp = report.created_at.strftime("%Y%m%d_%H%M%S")
                filename = f"enhanced_research_{safe_topic}_{timestamp}.md"
            
            # Generate full path
            file_path = self.reports_dir / filename
            
            # Generate markdown content
            markdown_content = self._build_enhanced_markdown_content(report)
            
            # Write to file
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
            
            logger.info(f"Enhanced research report saved to: {file_path.absolute()}")
            return str(file_path.absolute())
            
        except Exception as e:
            logger.error(f"Failed to save enhanced research report: {e}")
            raise
    
    def _build_enhanced_markdown_content(self, report: EnhancedResearchReport) -> str:
        """Build comprehensive markdown content without rigid divisions"""
        
        content = []
        
        # Header with metadata
        content.append(f"# æ·±åº¦ç ”ç©¶æŠ¥å‘Šï¼š{report.topic}")
        content.append("")
        content.append("---")
        content.append("")
        
        # Report metadata
        content.append("## ğŸ“Š æŠ¥å‘Šä¿¡æ¯")
        content.append("")
        content.append(f"- **ç ”ç©¶ä¸»é¢˜**: {report.topic}")
        content.append(f"- **æŠ¥å‘Šè¯­è¨€**: {report.language}")
        content.append(f"- **ç”Ÿæˆæ—¶é—´**: {report.created_at.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        content.append(f"- **ç ”ç©¶æ—¶é•¿**: {report.total_duration:.2f} ç§’")
        content.append(f"- **ç ”ç©¶æ­¥éª¤**: {len(report.steps)} ä¸ª")
        content.append(f"- **ä¿¡æ¯æ¥æº**: {len(report.sources)} ä¸ª")
        content.append("")
        
        # Provider statistics
        if report.provider_stats:
            content.append("### ğŸ” æ•°æ®æ¥æºç»Ÿè®¡")
            content.append("")
            for provider, count in report.provider_stats.items():
                if count > 0:
                    provider_name = {
                        'tavily': 'Tavily æœç´¢',
                        'searxng': 'SearXNG æœç´¢', 
                        'content_extraction': 'æ·±åº¦å†…å®¹æå–'
                    }.get(provider, provider)
                    content.append(f"- **{provider_name}**: {count} æ¬¡")
            content.append("")
        
        # Content analysis overview
        if report.content_analysis:
            stats = report.content_analysis.get('content_stats', {})
            if stats:
                content.append("### ğŸ“ˆ å†…å®¹åˆ†ææ¦‚è§ˆ")
                content.append("")
                if stats.get('total_words', 0) > 0:
                    content.append(f"- **æå–æ–‡å­—æ€»æ•°**: {stats['total_words']:,} å­—")
                if stats.get('tavily_results', 0) > 0:
                    content.append(f"- **Tavily æœç´¢ç»“æœ**: {stats['tavily_results']} æ¡")
                if stats.get('searxng_results', 0) > 0:
                    content.append(f"- **SearXNG æœç´¢ç»“æœ**: {stats['searxng_results']} æ¡")
                if stats.get('extracted_pages', 0) > 0:
                    content.append(f"- **æ·±åº¦æå–é¡µé¢**: {stats['extracted_pages']} ä¸ª")
                
                quality = report.content_analysis.get('analysis_quality', 'basic')
                quality_text = {'high': 'é«˜è´¨é‡', 'medium': 'ä¸­ç­‰è´¨é‡', 'basic': 'åŸºç¡€è´¨é‡'}.get(quality, quality)
                content.append(f"- **åˆ†æè´¨é‡**: {quality_text}")
                content.append("")
        
        # Executive Summary
        content.append("## ğŸ“‹ æ‰§è¡Œæ‘˜è¦")
        content.append("")
        content.append(report.executive_summary)
        content.append("")
        
        # Comprehensive Analysis (if available)
        if report.content_analysis and report.content_analysis.get('comprehensive_analysis'):
            content.append("## ğŸ”¬ ç»¼åˆåˆ†æ")
            content.append("")
            content.append(report.content_analysis['comprehensive_analysis'])
            content.append("")
        
        # Key Findings
        if report.key_findings:
            content.append("## ğŸ” å…³é”®å‘ç°")
            content.append("")
            for i, finding in enumerate(report.key_findings, 1):
                content.append(f"### {i}. {finding}")
                content.append("")
        
        # Detailed Research Steps
        content.append("## ğŸ“š è¯¦ç»†ç ”ç©¶è¿‡ç¨‹")
        content.append("")
        
        for step in report.steps:
            content.append(f"### æ­¥éª¤ {step.step_number}: {step.description}")
            content.append("")
            content.append(f"**æœç´¢æŸ¥è¯¢**: `{step.query}`")
            content.append(f"**æ‰§è¡Œæ—¶é—´**: {step.duration:.2f} ç§’")
            content.append("")
            
            # Data sources for this step
            sources_info = []
            if step.tavily_results:
                sources_info.append(f"Tavily: {len(step.tavily_results)} æ¡ç»“æœ")
            if step.searxng_results:
                sources_info.append(f"SearXNG: {len(step.searxng_results.results)} æ¡ç»“æœ")
            if step.extracted_content:
                sources_info.append(f"æ·±åº¦æå–: {len(step.extracted_content)} ä¸ªé¡µé¢")
            
            if sources_info:
                content.append(f"**æ•°æ®æ¥æº**: {' | '.join(sources_info)}")
                content.append("")
            
            # Step analysis
            if step.analysis:
                content.append("#### åˆ†æç»“æœ")
                content.append("")
                content.append(step.analysis)
                content.append("")
            
            # Detailed results (collapsible sections)
            if step.tavily_results or step.searxng_results or step.extracted_content:
                content.append("<details>")
                content.append("<summary>ğŸ“Š è¯¦ç»†æœç´¢ç»“æœ</summary>")
                content.append("")
                
                # Tavily results
                if step.tavily_results:
                    content.append("**Tavily æœç´¢ç»“æœ:**")
                    content.append("")
                    for i, result in enumerate(step.tavily_results[:5], 1):
                        content.append(f"{i}. [{result.get('title', 'No title')}]({result.get('url', '#')})")
                        if result.get('content'):
                            content.append(f"   > {result['content'][:200]}...")
                        content.append("")
                
                # SearXNG results
                if step.searxng_results:
                    content.append("**SearXNG æœç´¢ç»“æœ:**")
                    content.append("")
                    for i, result in enumerate(step.searxng_results.results[:5], 1):
                        content.append(f"{i}. [{result.title}]({result.url})")
                        if result.content:
                            content.append(f"   > {result.content[:200]}...")
                        content.append("")
                
                # Extracted content
                if step.extracted_content:
                    content.append("**æ·±åº¦å†…å®¹æå–:**")
                    content.append("")
                    for i, extracted in enumerate(step.extracted_content[:3], 1):
                        content.append(f"{i}. [{extracted.title}]({extracted.url}) ({extracted.word_count} å­—)")
                        if extracted.content:
                            content.append(f"   > {extracted.content[:300]}...")
                        content.append("")
                
                content.append("</details>")
                content.append("")
        
        # Recommendations
        if report.recommendations:
            content.append("## ğŸ’¡ å»ºè®®ä¸æ¨è")
            content.append("")
            for i, recommendation in enumerate(report.recommendations, 1):
                content.append(f"### {i}. {recommendation}")
                content.append("")
        
        # Sources
        if report.sources:
            content.append("## ğŸ“– å‚è€ƒæ¥æº")
            content.append("")
            for i, source in enumerate(report.sources, 1):
                content.append(f"{i}. {source}")
            content.append("")
        
        # Footer
        content.append("---")
        content.append("")
        content.append("*æœ¬æŠ¥å‘Šç”± LandPPT å¢å¼ºç ”ç©¶ç³»ç»Ÿç”Ÿæˆ*")
        content.append("")
        content.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}")
        
        return "\n".join(content)
    
    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for safe file system usage"""
        # Remove or replace invalid characters
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # Remove extra spaces and limit length
        filename = re.sub(r'\s+', '_', filename.strip())
        return filename[:50] if len(filename) > 50 else filename
    
    def list_reports(self) -> List[Dict[str, Any]]:
        """List all saved research reports"""
        reports = []
        
        try:
            for file_path in self.reports_dir.glob("*.md"):
                if file_path.is_file():
                    stat = file_path.stat()
                    reports.append({
                        'filename': file_path.name,
                        'path': str(file_path.absolute()),
                        'size': stat.st_size,
                        'created': datetime.fromtimestamp(stat.st_ctime),
                        'modified': datetime.fromtimestamp(stat.st_mtime)
                    })
            
            # Sort by modification time (newest first)
            reports.sort(key=lambda x: x['modified'], reverse=True)
            
        except Exception as e:
            logger.error(f"Failed to list reports: {e}")
        
        return reports
