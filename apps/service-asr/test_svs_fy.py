#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASR SenseVoice + Qwen ç¿»è¯‘ å®æ—¶è¯­éŸ³ç¿»è¯‘ç³»ç»Ÿ
æœ¬åœ°è¯­éŸ³è¯†åˆ« + åœ¨çº¿ç¿»è¯‘å¯¹ç…§æ˜¾ç¤º
"""

import os
import sys
from pathlib import Path

# è®¾ç½®ModelScopeç¼“å­˜ç›®å½•
os.environ['MODELSCOPE_CACHE'] = str(Path(__file__).parent / "models")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['PYTHONIOENCODING'] = 'utf-8'

# åŠ è½½ .env æ–‡ä»¶
from dotenv import load_dotenv
env_path = Path(__file__).parent / ".env"
load_dotenv(env_path)

# PyAudio æ£€æŸ¥
try:
    import pyaudio
except ImportError:
    print("âŒ PyAudio æœªå®‰è£…")
    print("   å®‰è£…: sudo pacman -S python-pyaudio")
    sys.exit(1)

import time
import logging
import numpy as np
import asyncio
import httpx
from collections import deque
import audioop
import re
from typing import Optional

# æŠ‘åˆ¶ tqdm è¾“å‡º
class TqdmSilence:
    def write(self, msg): pass
    def flush(self): pass

class TqdmSuppressor:
    def __enter__(self):
        self.stdout = sys.stdout
        self.stderr = sys.stderr
        sys.stdout = TqdmSilence()
        sys.stderr = TqdmSilence()
    def __exit__(self, *args):
        sys.stdout = self.stdout
        sys.stderr = self.stderr

# å¯¼å…¥ FunASR
with TqdmSuppressor():
    from funasr import AutoModel

# ========================================
# é…ç½®å‚æ•°
# ========================================
SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_SIZE = 1200  # 75ms

# è¯­éŸ³è¯†åˆ«è¯­è¨€
LANGUAGE = "en"  # zh=ä¸­æ–‡, en=è‹±æ–‡, ja=æ—¥è¯­

# ç¿»è¯‘é…ç½®
TRANSLATION_MODE = "en2zh"  # zh2en=ä¸­è¯‘è‹±, en2zh=è‹±è¯‘ä¸­
TRANSLATION_MODEL = "qwen-mt-flash"  # æˆ– qwen-mt-lite

# çº é”™é…ç½®
ENABLE_CORRECTION = True  # å¯ç”¨è¯†åˆ«ç»“æœçº é”™
CORRECTION_MODEL = "qwen-plus"  # çº é”™æ¨¡å‹ï¼šqwen-turbo, qwen-plus, qwen-max

# æ–­å¥é…ç½®ï¼ˆå’Œ test_svs.py ä¿æŒä¸€è‡´ï¼‰
SILENCE_THRESHOLD = 0.01
MAX_SILENCE_DURATION = 0.7
MIN_SENTENCE_DURATION = 0.5
MAX_SENTENCE_DURATION = 12.0
INFERENCE_INTERVAL = 0.1

# ç¿»è¯‘ä¸“ç”¨ï¼šæ–­å¥ç­‰å¾…æ—¶é—´ï¼ˆç¨å¾®å»¶è¿Ÿä¸€ç‚¹æ–­å¥ï¼Œè®©å¥å­æ›´å®Œæ•´ï¼‰
TRANSLATION_WAIT_TIME = 0.3  # æ–­å¥åç­‰å¾…0.3ç§’å†ç¿»è¯‘

# Qwen API é…ç½®
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY", "")
QWEN_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

# ========================================
# æ—¥å¿—é…ç½®
# ========================================
log_dir = Path(__file__).parent / "log"
log_dir.mkdir(exist_ok=True)
log_file = log_dir / "translation.log"

# è·å–æ ¹æ—¥å¿—å™¨ï¼ˆç¡®ä¿å…¨å±€æœ‰æ•ˆï¼‰
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)

# æ¸…é™¤æ‰€æœ‰ç°æœ‰çš„ handlers
root_logger.handlers.clear()

# æ–‡ä»¶å¤„ç†å™¨ - è¯¦ç»†æ—¥å¿—
file_handler = logging.FileHandler(log_file, encoding='utf-8')
file_handler.setLevel(logging.INFO)
file_formatter = logging.Formatter(
    '%(asctime)s | %(message)s',
    datefmt='%H:%M:%S'
)
file_handler.setFormatter(file_formatter)
root_logger.addHandler(file_handler)

# æ§åˆ¶å°å¤„ç†å™¨ - ç®€æ´è¾“å‡º
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(message)s')
console_handler.setFormatter(console_formatter)
root_logger.addHandler(console_handler)

# åˆ›å»ºä¸» loggerï¼ˆç»§æ‰¿æ ¹æ—¥å¿—å™¨é…ç½®ï¼‰
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# ç«‹å³å†™å…¥æµ‹è¯•æ—¥å¿—å¹¶å¼ºåˆ¶ flushï¼ŒéªŒè¯æ–‡ä»¶å†™å…¥
logger.info("=" * 70)
logger.info("ğŸš€ å®æ—¶è¯­éŸ³ç¿»è¯‘ç³»ç»Ÿæ—¥å¿—åˆå§‹åŒ–å®Œæˆ")
logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
logger.info("=" * 70)

# å¼ºåˆ¶ flush ç¡®ä¿æ—¥å¿—å†™å…¥æ–‡ä»¶
for handler in root_logger.handlers:
    handler.flush()

# ========================================
# Qwen çº é”™å®¢æˆ·ç«¯
# ========================================
class QwenCorrector:
    """Qwen æ–‡æœ¬çº é”™å®¢æˆ·ç«¯ - ä¿®æ­£è¯­éŸ³è¯†åˆ«é”™è¯¯"""

    def __init__(self, api_key: str, model: str = "qwen-plus"):
        self.api_key = api_key
        self.model = model
        self.client = None
        logger.info(f"ğŸ”§ çº é”™æ¨¡å‹: {model}")

    async def init(self):
        """åˆå§‹åŒ– HTTP å®¢æˆ·ç«¯"""
        self.client = httpx.AsyncClient(
            base_url=QWEN_BASE_URL,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            },
            timeout=10.0
        )

    async def correct(self, text: str, context: str = "") -> Optional[str]:
        """
        çº æ­£è¯­éŸ³è¯†åˆ«é”™è¯¯

        Args:
            text: éœ€è¦çº é”™çš„æ–‡æœ¬
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå‰æ–‡ï¼‰
        """
        if not text or not self.client:
            return None

        # æ„å»ºçº é”™ prompt
        if context:
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³è¯†åˆ«ç»“æœçº é”™ä¸“å®¶ã€‚è¯·ä¿®æ­£ä»¥ä¸‹è¯­éŸ³è¯†åˆ«æ–‡æœ¬ä¸­çš„é”™è¯¯ã€‚

ä¸Šä¸‹æ–‡ï¼ˆå‰æ–‡ï¼‰ï¼š{context}

å½“å‰è¯†åˆ«æ–‡æœ¬ï¼š{text}

è¦æ±‚ï¼š
1. ä¿®æ­£æ˜æ˜¾çš„è¯­éŸ³è¯†åˆ«é”™è¯¯ï¼ˆå¦‚åŒéŸ³å­—ã€æ¼å­—ã€é”™å­—ï¼‰
2. ä¿æŒåŸæ–‡çš„è¯­ä¹‰å’Œè¯­æ°”
3. ç‰¹åˆ«æ³¨æ„äººåã€åœ°åã€æ–‡å­¦ä½œå“çš„å‡†ç¡®æ€§
4. åªè¾“å‡ºä¿®æ­£åçš„æ–‡æœ¬ï¼Œä¸è¦è§£é‡Š

ä¿®æ­£åçš„æ–‡æœ¬ï¼š"""
        else:
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªè¯­éŸ³è¯†åˆ«ç»“æœçº é”™ä¸“å®¶ã€‚è¯·ä¿®æ­£ä»¥ä¸‹è¯­éŸ³è¯†åˆ«æ–‡æœ¬ä¸­çš„é”™è¯¯ã€‚

è¯†åˆ«æ–‡æœ¬ï¼š{text}

è¦æ±‚ï¼š
1. ä¿®æ­£æ˜æ˜¾çš„è¯­éŸ³è¯†åˆ«é”™è¯¯ï¼ˆå¦‚åŒéŸ³å­—ã€æ¼å­—ã€é”™å­—ï¼‰
2. ä¿æŒåŸæ–‡çš„è¯­ä¹‰å’Œè¯­æ°”
3. ç‰¹åˆ«æ³¨æ„äººåã€åœ°åã€æ–‡å­¦ä½œå“çš„å‡†ç¡®æ€§
4. åªè¾“å‡ºä¿®æ­£åçš„æ–‡æœ¬ï¼Œä¸è¦è§£é‡Š

ä¿®æ­£åçš„æ–‡æœ¬ï¼š"""

        try:
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.1,  # ä½æ¸©åº¦ä¿è¯ç¨³å®šæ€§
                "max_tokens": 200
            }

            response = await self.client.post("/", json=payload)
            response.raise_for_status()

            result = response.json()
            corrected = result.get("choices", [{}])[0].get("message", {}).get("content", "")

            return corrected.strip() if corrected else None

        except Exception as e:
            logger.error(f"çº é”™å¤±è´¥: {e}")
            return None

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()

# ========================================
# Qwen ç¿»è¯‘å®¢æˆ·ç«¯
# ========================================
class QwenTranslator:
    """Qwen ç¿»è¯‘å®¢æˆ·ç«¯"""

    def __init__(self, api_key: str, mode: str = "zh2en"):
        self.api_key = api_key
        self.mode = mode
        self.client = None

        # ç¿»è¯‘æ–¹å‘é…ç½®
        if mode == "zh2en":
            self.source_lang = "zh"
            self.target_lang = "English"
            self.display_name = "ä¸­è¯‘è‹±"
        elif mode == "en2zh":
            self.source_lang = "en"
            self.target_lang = "Chinese"
            self.display_name = "è‹±è¯‘ä¸­"
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ç¿»è¯‘æ¨¡å¼: {mode}")

        logger.info(f"ğŸŒ ç¿»è¯‘æ¨¡å¼: {self.display_name}")

    async def init(self):
        """åˆå§‹åŒ– HTTP å®¢æˆ·ç«¯"""
        self.client = httpx.AsyncClient(
            base_url=QWEN_BASE_URL,
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            },
            timeout=10.0
        )

    async def translate(self, text: str) -> Optional[str]:
        """ç¿»è¯‘æ–‡æœ¬"""
        if not text or not self.client:
            return None

        try:
            payload = {
                "model": TRANSLATION_MODEL,
                "messages": [{"role": "user", "content": text}],
                "translation_options": {
                    "source_lang": "auto" if self.mode == "zh2en" else "English",
                    "target_lang": self.target_lang
                }
            }

            response = await self.client.post("/", json=payload)
            response.raise_for_status()

            result = response.json()
            translated = result.get("choices", [{}])[0].get("message", {}).get("content", "")

            return translated.strip() if translated else None

        except Exception as e:
            logger.error(f"ç¿»è¯‘å¤±è´¥: {e}")
            return None

    async def close(self):
        """å…³é—­å®¢æˆ·ç«¯"""
        if self.client:
            await self.client.aclose()

# ========================================
# è¯­éŸ³è¯†åˆ«å¼•æ“
# ========================================
class StreamingRecognizer:
    """æµå¼è¯­éŸ³è¯†åˆ«"""

    def __init__(self):
        logger.info("ğŸ”„ åŠ è½½ SenseVoice æ¨¡å‹...")
        load_start = time.time()

        with TqdmSuppressor():
            self.model = AutoModel(
                model="iic/SenseVoiceSmall",
                vad_model="fsmn-vad",
                vad_kwargs={"max_single_segment_time": 30000},
                device="cpu",
                disable_update=True
            )

        logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({time.time() - load_start:.2f}s)")

        # çŠ¶æ€ï¼ˆå’Œ test_svs.py å®Œå…¨ä¸€è‡´ï¼‰
        self.buffer = []
        self.committed_text = ""   # å·²æäº¤çš„æ–‡æœ¬
        self.current_text = ""     # å½“å‰æ­£åœ¨è¯†åˆ«çš„æ–‡æœ¬
        self.silence_time = 0.0
        self.sentence_time = 0.0

        # æ€§èƒ½è¿½è¸ª
        self.last_inference_time = 0.0
        self.last_recognition_time = time.time()

    def process(self, audio_data, rms_energy):
        """å¤„ç†éŸ³é¢‘"""
        chunk_duration = len(audio_data) / 2 / SAMPLE_RATE

        self.buffer.append(audio_data)
        self.sentence_time += chunk_duration

        # é™éŸ³æ£€æµ‹
        if rms_energy < SILENCE_THRESHOLD:
            self.silence_time += chunk_duration
        else:
            self.silence_time = 0.0

        # åŠ¨æ€æ–­å¥
        dynamic_silence = MAX_SILENCE_DURATION
        if self.sentence_time > 5.0:
            dynamic_silence = 0.5
        elif self.sentence_time > 8.0:
            dynamic_silence = 0.3

        current_time = time.time()
        should_recognize = (
            self.silence_time > dynamic_silence or
            self.sentence_time >= MAX_SENTENCE_DURATION or
            (current_time - getattr(self, 'last_inference_time', 0)) >= INFERENCE_INTERVAL
        )

        if not should_recognize:
            return None

        self.last_inference_time = current_time
        inference_start = time.time()

        combined = b''.join(self.buffer)

        try:
            audio_np = np.frombuffer(combined, dtype=np.int16).astype(np.float32) / 32768.0

            with TqdmSuppressor():
                result = self.model.generate(
                    input=audio_np,
                    cache={},
                    language=LANGUAGE,
                    use_itn=True,
                    batch_size_s=60
                )

            inference_time = (time.time() - inference_start) * 1000

            if result and len(result) > 0:
                raw_text = result[0].get("text", "")
                text = re.sub(r'<\|[^|]+\|>', '', raw_text).strip()

                if text:
                    # æ›´æ–°å½“å‰æ–‡æœ¬ï¼ˆç”¨äºä¸­é—´ç»“æœæ˜¾ç¤ºï¼‰
                    self.current_text = text

                    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ–­å¥ï¼ˆå’Œ test_svs.py å®Œå…¨ä¸€è‡´çš„é€»è¾‘ï¼‰
                    is_punctuation_end = text.endswith(('ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!', 'ï¼Œ', ','))
                    is_long_stable = self.sentence_time > 2.0 and is_punctuation_end

                    # ä¸‰ç§æ–­å¥è§¦å‘æ¡ä»¶
                    is_silence_trigger = self.silence_time > dynamic_silence
                    is_forced_cut = self.sentence_time >= MAX_SENTENCE_DURATION

                    should_commit = (
                        is_silence_trigger or
                        is_forced_cut or
                        is_long_stable
                    )

                    if should_commit:
                        # ç¡®å®šæ–­å¥åŸå› 
                        if is_forced_cut:
                            cut_reason = "force"
                        elif is_long_stable:
                            cut_reason = "punctuation"
                        else:
                            cut_reason = "silence"

                        # æäº¤å¥å­
                        self.committed_text += text

                        # æ¸…ç©ºç¼“å­˜
                        self.buffer = []
                        self.silence_time = 0.0
                        self.sentence_time = 0.0

                        return {
                            'text': text,
                            'is_final': True,
                            'time_ms': inference_time,
                            'cut_reason': cut_reason,
                            'total_text': self.committed_text  # æ·»åŠ å®Œæ•´æ–‡æœ¬
                        }

        except Exception as e:
            logger.error(f"è¯†åˆ«é”™è¯¯: {e}")

        return None

# ========================================
# éº¦å…‹é£æ•è·
# ========================================
class MicrophoneCapture:
    """éº¦å…‹é£æ•è·"""

    def __init__(self, rate=16000, channels=1, chunk_size=1200):
        self.rate = rate
        self.channels = channels
        self.chunk_size = chunk_size
        self.is_running = False
        self.p = None
        self.stream = None

    def start(self):
        self.p = pyaudio.PyAudio()

        try:
            default = self.p.get_default_input_device_info()
            device_index = default['index']
            logger.info(f"ğŸ¤ éº¦å…‹é£: {default['name'][:40]}")
        except:
            device_index = 0

        self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=self.channels,
            rate=self.rate,
            input=True,
            input_device_index=device_index,
            frames_per_buffer=self.chunk_size
        )

        self.is_running = True
        logger.info(f"âœ… éº¦å…‹é£å·²å¯åŠ¨ ({self.rate}Hz)")

    def read(self):
        if not self.is_running:
            return None

        try:
            data = self.stream.read(self.chunk_size, exception_on_overflow=False)
            rms = audioop.rms(data, 2) / 32768.0
            return {'data': data, 'rms': rms}
        except:
            return None

    def stop(self):
        self.is_running = False
        if self.stream:
            self.stream.close()
        if self.p:
            self.p.terminate()

# ========================================
# ä¸»ç¨‹åº
# ========================================
async def main():
    if not DASHSCOPE_API_KEY:
        print("âŒ æœªæ‰¾åˆ° DASHSCOPE_API_KEY")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® API Key")
        return

    mode_display = {"zh2en": "ä¸­æ–‡ â†’ English", "en2zh": "English â†’ ä¸­æ–‡"}
    lang_display = {"zh": "ä¸­æ–‡", "en": "è‹±æ–‡"}

    correction_status = f"âœ… å·²å¯ç”¨ ({CORRECTION_MODEL})" if ENABLE_CORRECTION else "âŒ æœªå¯ç”¨"

    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        å®æ—¶è¯­éŸ³ç¿»è¯‘ç³»ç»Ÿ (FunASR + Qwen)                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  é…ç½®:                                                        â•‘
â•‘    â€¢ è¯†åˆ«è¯­è¨€: {lang_display.get(LANGUAGE, LANGUAGE):<10s}                                 â•‘
â•‘    â€¢ ç¿»è¯‘æ–¹å‘: {mode_display.get(TRANSLATION_MODE, TRANSLATION_MODE):<20s}                    â•‘
â•‘    â€¢ ç¿»è¯‘æ¨¡å‹: {TRANSLATION_MODEL:<20s}                          â•‘
â•‘    â€¢ æ™ºèƒ½çº é”™: {correction_status:<20s}                          â•‘
â•‘                                                              â•‘
â•‘  å¤„ç†æµç¨‹:                                                    â•‘
â•‘    1ï¸âƒ£  è¯­éŸ³è¯†åˆ« â†’ 2ï¸âƒ£  æ™ºèƒ½çº é”™ â†’ 3ï¸âƒ£  ç¿»è¯‘è¾“å‡º                      â•‘
â•‘                                                              â•‘
â•‘  æŒ‰ Ctrl+C åœæ­¢                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    # åˆå§‹åŒ–
    translator = QwenTranslator(DASHSCOPE_API_KEY, TRANSLATION_MODE)
    await translator.init()

    # çº é”™å™¨ï¼ˆå¯é€‰ï¼‰
    corrector = None
    if ENABLE_CORRECTION:
        corrector = QwenCorrector(DASHSCOPE_API_KEY, CORRECTION_MODEL)
        await corrector.init()

    recognizer = StreamingRecognizer()
    mic = MicrophoneCapture(rate=SAMPLE_RATE, channels=CHANNELS, chunk_size=CHUNK_SIZE)
    mic.start()

    stats = {"recognized": 0, "corrected": 0, "translated": 0, "failed": 0, "cuts": {"silence": 0, "force": 0, "punctuation": 0}}

    # ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆç”¨äºçº é”™ï¼‰
    context_memory = []

    try:
        while True:
            audio_item = mic.read()
            if audio_item is None:
                continue

            result = recognizer.process(audio_item['data'], audio_item['rms'])

            if result and result.get('is_final'):
                text = result['text']
                cut_reason = result.get('cut_reason', 'unknown')
                stats["recognized"] += 1
                stats["cuts"][cut_reason] += 1

                # æ˜¾ç¤ºåŸæ–‡ï¼ˆå¸¦æ–­å¥åŸå› ï¼‰
                reason_symbols = {"silence": "â¸ï¸", "force": "âš¡", "punctuation": "âœ‚ï¸"}
                symbol = reason_symbols.get(cut_reason, "â€¢")
                print(f"\r{symbol} [{cut_reason:10s}] {text}")

                # è·å–ä¸Šä¸‹æ–‡ï¼ˆæœ€è¿‘3å¥ï¼‰
                context = " ".join(context_memory[-3:]) if context_memory else ""

                # çº é”™ï¼ˆå¯é€‰ï¼‰
                corrected_text = text
                if ENABLE_CORRECTION and corrector:
                    print(f"ğŸ”§ çº é”™ä¸­...", end='', flush=True)
                    corrected = await corrector.correct(text, context)
                    if corrected and corrected != text:
                        corrected_text = corrected
                        stats["corrected"] += 1
                        print(f"\râœ… å·²ä¿®æ­£: {corrected_text}")
                    else:
                        print(f"\râŠ™ æ— éœ€ä¿®æ­£")

                # æ›´æ–°ä¸Šä¸‹æ–‡è®°å¿†
                context_memory.append(corrected_text)
                if len(context_memory) > 5:  # åªä¿ç•™æœ€è¿‘5å¥
                    context_memory.pop(0)

                # ç¿»è¯‘
                translation = await translator.translate(corrected_text)

                if translation:
                    stats["translated"] += 1
                    # æ˜¾ç¤ºè¯‘æ–‡
                    print(f"ğŸŒ è¯‘æ–‡: {translation}")

                    # è®°å½•æ—¥å¿—
                    if corrected_text != text:
                        logger.info(f"[{cut_reason}] åŸæ–‡: {text} | ä¿®æ­£: {corrected_text} | è¯‘æ–‡: {translation}")
                    else:
                        logger.info(f"[{cut_reason}] {corrected_text} | {translation}")

                    # å®æ—¶ flush æ—¥å¿—åˆ°æ–‡ä»¶
                    for handler in logging.getLogger().handlers:
                        if isinstance(handler, logging.FileHandler):
                            handler.flush()
                else:
                    stats["failed"] += 1
                    print(f"âš ï¸  ç¿»è¯‘å¤±è´¥")

                print()  # ç©ºè¡Œåˆ†éš”

    except KeyboardInterrupt:
        print("\n\n" + "=" * 60)
        print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 60)
        print(f"è¯†åˆ«å¥å­: {stats['recognized']}")
        if ENABLE_CORRECTION:
            print(f"çº é”™ä¿®æ­£: {stats['corrected']}")
        print(f"ç¿»è¯‘æˆåŠŸ: {stats['translated']}")
        print(f"ç¿»è¯‘å¤±è´¥: {stats['failed']}")
        if stats['recognized'] > 0:
            success_rate = stats['translated'] / stats['recognized'] * 100
            print(f"æˆåŠŸç‡:   {success_rate:.1f}%")
        print()
        print("æ–­å¥ç»Ÿè®¡:")
        print(f"  é™éŸ³æ–­å¥: {stats['cuts']['silence']}")
        print(f"  å¼ºåˆ¶æ–­å¥: {stats['cuts']['force']}")
        print(f"  æ ‡ç‚¹æ–­å¥: {stats['cuts']['punctuation']}")
    finally:
        mic.stop()
        await translator.close()
        if corrector:
            await corrector.close()

        # ç¡®ä¿æ‰€æœ‰æ—¥å¿—å†™å…¥æ–‡ä»¶
        for handler in logging.getLogger().handlers:
            if isinstance(handler, logging.FileHandler):
                handler.flush()
                handler.close()

        logger.info(f"ğŸ“ è¯¦ç»†æ—¥å¿—: {log_file}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
