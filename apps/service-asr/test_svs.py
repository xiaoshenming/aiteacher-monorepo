#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FunASR SenseVoice æœ¬åœ°å®æ—¶è¯†åˆ«æµ‹è¯•
ç›´æ¥åŠ è½½æ¨¡å‹ï¼Œæœ¬åœ°éº¦å…‹é£å®æ—¶è¯†åˆ«ï¼Œä¸èµ° WebSocket
ç”¨äºè¯Šæ–­æ¨¡å‹æœ¬èº«çš„æ€§èƒ½å’Œæ–­å¥é—®é¢˜
"""

import os
import sys
from pathlib import Path

# è®¾ç½®ModelScopeç¼“å­˜ç›®å½•åˆ°æœ¬åœ° ./models æ–‡ä»¶å¤¹
# å¿…é¡»åœ¨å¯¼å…¥ funasr ä¹‹å‰è®¾ç½®
os.environ['MODELSCOPE_CACHE'] = str(Path(__file__).parent / "models")

# æŠ‘åˆ¶ FunASR çš„ tqdm è¿›åº¦æ¡è¾“å‡º
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
os.environ['PYTHONIOENCODING'] = 'utf-8'

# å…ˆæ£€æŸ¥ PyAudio
try:
    import pyaudio
    MIC_AVAILABLE = True
except ImportError:
    MIC_AVAILABLE = False
    print("âŒ PyAudio æœªå®‰è£…")
    print("   å®‰è£…æ–¹æ³•:")
    print("   - Arch Linux: sudo pacman -S python-pyaudio")
    print("   - pip: pip install pyaudio")
    sys.exit(1)

# ç„¶åå¯¼å…¥å…¶ä»–æ¨¡å—
import time
import queue
import logging
import numpy as np
from datetime import datetime
from collections import deque
import audioop

# æŠ‘åˆ¶ tqdm å’Œ FunASR çš„æ—¥å¿—è¾“å‡º
class TqdmSilence:
    """æŠ‘åˆ¶ tqdm è¾“å‡º"""
    def write(self, msg):
        pass  # ä»€ä¹ˆéƒ½ä¸è¾“å‡º
    def flush(self):
        pass

class TqdmSuppressor:
    def __enter__(self):
        self.original_stdout = sys.stdout
        self.original_stderr = sys.stderr
        sys.stdout = TqdmSilence()
        sys.stderr = TqdmSilence()
    def __exit__(self, *args):
        sys.stdout = self.original_stdout
        sys.stderr = self.original_stderr

# å¯¼å…¥ FunASR æ—¶æŠ‘åˆ¶è¾“å‡º
with TqdmSuppressor():
    from funasr import AutoModel

# ========================================
# é…ç½®å‚æ•°
# ========================================
SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_SIZE = 1200  # 75ms chunks (æ¸©å’Œä¼˜åŒ–ï¼Œä»100msé™åˆ°75ms)

# è¯­è¨€é…ç½® (zh=ä¸­æ–‡, en=è‹±æ–‡, ja=æ—¥è¯­, ko=éŸ©è¯­, yue=ç²¤è¯­, auto=è‡ªåŠ¨)
LANGUAGE = "zh"  # é»˜è®¤å¼ºåˆ¶ä¸­æ–‡è¯†åˆ«ï¼Œé¿å…è¯¯è¯†åˆ«ä¸ºæ—¥è¯­

# æ–­å¥é…ç½®ï¼ˆæ¸©å’Œä¼˜åŒ–ï¼‰
SILENCE_THRESHOLD = 0.01      # é™éŸ³é˜ˆå€¼ (0-1), RMSå½’ä¸€åŒ–å€¼
MAX_SILENCE_DURATION = 0.7    # é™éŸ³å¤šä¹…åæ–­å¥(ç§’) - ä»0.8é™åˆ°0.7
MIN_SENTENCE_DURATION = 0.5   # å¥å­æœ€çŸ­æ—¶é•¿(ç§’)
MAX_SENTENCE_DURATION = 12.0  # å¥å­æœ€é•¿æ—¶é•¿ï¼Œå¼ºåˆ¶æ–­å¥(ç§’) - ä»15é™åˆ°12
INFERENCE_INTERVAL = 0.1      # è¯†åˆ«é—´éš”(ç§’)

# ========================================
# æ—¥å¿—é…ç½®
# ========================================
log_dir = Path(__file__).parent / "log"
log_dir.mkdir(exist_ok=True)
log_file = log_dir / "debug.log"

# è·å–æ ¹æ—¥å¿—å™¨
root_logger = logging.getLogger()
root_logger.setLevel(logging.DEBUG)

# æ¸…é™¤ç°æœ‰çš„ handlersï¼ˆå¦‚æœæœ‰ï¼‰
root_logger.handlers.clear()

# æ–‡ä»¶å¤„ç†å™¨ - è¯¦ç»†æ—¥å¿—
file_handler = logging.FileHandler(log_file, encoding='utf-8')
file_handler.setLevel(logging.DEBUG)
file_formatter = logging.Formatter(
    '%(asctime)s | %(levelname)-8s | [%(name)s:%(lineno)d] | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
file_handler.setFormatter(file_formatter)
root_logger.addHandler(file_handler)

# æ§åˆ¶å°å¤„ç†å™¨ - åªæ˜¾ç¤º INFO åŠä»¥ä¸Šï¼Œç®€æ´æ ¼å¼
console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(levelname)s: %(message)s')
console_handler.setFormatter(console_formatter)
root_logger.addHandler(console_handler)

# åˆ›å»ºä¸» logger
logger = logging.getLogger(__name__)

# ç«‹å³å†™å…¥æµ‹è¯•æ—¥å¿—å¹¶ flushï¼ŒéªŒè¯æ–‡ä»¶å†™å…¥
logger.info("=" * 70)
logger.info("ğŸš€ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
logger.info("=" * 70)
# å¼ºåˆ¶ flush ç¡®ä¿æ—¥å¿—å†™å…¥æ–‡ä»¶
for handler in root_logger.handlers:
    handler.flush()

# ========================================
# æ€§èƒ½ç»Ÿè®¡
# ========================================
class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.start_time = time.time()
        self.audio_chunks = 0
        self.inference_count = 0
        self.sentence_count = 0

        # å»¶è¿Ÿç»Ÿè®¡ (æ¯«ç§’)
        self.inference_times = deque(maxlen=100)
        self.end_to_end_latencies = deque(maxlen=100)

        # æ–­å¥ç»Ÿè®¡
        self.sentence_cuts = {
            "silence": 0,
            "force": 0,
            "punctuation": 0
        }

        # éŸ³é¢‘èƒ½é‡ç»Ÿè®¡
        self.energy_levels = deque(maxlen=1000)

        # å½“å‰å¥å­çŠ¶æ€
        self.current_sentence_start = None
        self.sentence_durations = deque(maxlen=50)

    def record_inference(self, inference_time_ms):
        self.inference_count += 1
        self.inference_times.append(inference_time_ms)

    def record_sentence_cut(self, reason, duration):
        self.sentence_count += 1
        if reason in self.sentence_cuts:
            self.sentence_cuts[reason] += 1
        if duration:
            self.sentence_durations.append(duration)

    def record_energy(self, energy):
        self.energy_levels.append(energy)

    def get_report(self):
        runtime = time.time() - self.start_time

        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                      ğŸ” æ€§èƒ½åˆ†ææŠ¥å‘Š                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ è¿è¡Œç»Ÿè®¡:                                                            â•‘
â•‘   è¿è¡Œæ—¶é•¿:        {runtime:10.1f} ç§’                                   â•‘
â•‘   æ¥æ”¶éŸ³é¢‘å—:      {self.audio_chunks:10d} å—                                  â•‘
â•‘   æ‰§è¡Œè¯†åˆ«æ¬¡æ•°:    {self.inference_count:10d} æ¬¡                                  â•‘
â•‘   æ–­å¥æ•°é‡:        {self.sentence_count:10d} å¥                                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ æ¨ç†æ€§èƒ½:                                                            â•‘
â•‘"""

        if self.inference_times:
            inference_array = np.array(self.inference_times)
            report += f"""â•‘   å¹³å‡æ¨ç†æ—¶é—´:    {np.mean(inference_array):10.1f} ms                                 â•‘
â•‘   ä¸­ä½æ•°æ¨ç†:      {np.median(inference_array):10.1f} ms                                 â•‘
â•‘   æœ€å¤§æ¨ç†æ—¶é—´:    {np.max(inference_array):10.1f} ms                                 â•‘
â•‘   æœ€å°æ¨ç†æ—¶é—´:    {np.min(inference_array):10.1f} ms                                 â•‘
â•‘   P95 æ¨ç†æ—¶é—´:    {np.percentile(inference_array, 95):10.1f} ms                                 â•‘
â•‘   P99 æ¨ç†æ—¶é—´:    {np.percentile(inference_array, 99):10.1f} ms                                 â•‘
"""
        else:
            report += f"""â•‘   æš‚æ— æ¨ç†æ•°æ®                                                        â•‘
"""

        report += f"""â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ æ–­å¥åˆ†æ:                                                            â•‘
â•‘   é™éŸ³æ–­å¥:        {self.sentence_cuts['silence']:10d} æ¬¡                                  â•‘
â•‘   å¼ºåˆ¶æ–­å¥:        {self.sentence_cuts['force']:10d} æ¬¡                                  â•‘
â•‘   æ ‡ç‚¹æ–­å¥:        {self.sentence_cuts['punctuation']:10d} æ¬¡                                  â•‘
"""

        if self.sentence_durations:
            duration_array = np.array(self.sentence_durations)
            report += f"""â•‘                                                                   â•‘
â•‘   å¹³å‡å¥å­é•¿åº¦:    {np.mean(duration_array):10.2f} ç§’                                 â•‘
â•‘   æœ€çŸ­å¥å­:        {np.min(duration_array):10.2f} ç§’                                 â•‘
â•‘   æœ€é•¿å¥å­:        {np.max(duration_array):10.2f} ç§’                                 â•‘
"""

        if self.energy_levels:
            energy_array = np.array(self.energy_levels)
            report += f"""â•‘                                                                   â•‘
â•‘   å¹³å‡éŸ³é¢‘èƒ½é‡:    {np.mean(energy_array):10.4f} RMS                                â•‘
â•‘   æœ€å¤§éŸ³é¢‘èƒ½é‡:    {np.max(energy_array):10.4f} RMS                                â•‘
â•‘   æœ€å°éŸ³é¢‘èƒ½é‡:    {np.min(energy_array):10.4f} RMS                                â•‘
"""

        report += f"""â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ å®æ—¶ç‡è®¡ç®—: (å¤„ç†æ—¶é—´ / éŸ³é¢‘æ—¶é•¿ï¼Œè¶Šå°è¶Šå¥½)                        â•‘
â•‘   ç›®æ ‡å®æ—¶ç‡: < 1.0 (å¯å®æ—¶å¤„ç†)                                   â•‘
â•‘   å½“å‰å®æ—¶ç‡: {np.mean(self.inference_times)/1000/INFERENCE_INTERVAL if self.inference_times else 0:10.2f}                                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return report

monitor = PerformanceMonitor()

# ========================================
# éº¦å…‹é£æ•è·
# ========================================
try:
    import pyaudio
    MIC_AVAILABLE = True
except ImportError:
    MIC_AVAILABLE = False
    logger.error("âŒ PyAudio æœªå®‰è£…")
    logger.error("   å®‰è£…æ–¹æ³•:")
    logger.error("   - Arch Linux: sudo pacman -S python-pyaudio")
    logger.error("   - pip: pip install pyaudio")
    sys.exit(1)


class MicrophoneCapture:
    """æœ¬åœ°éº¦å…‹é£éŸ³é¢‘æ•è· - ä½¿ç”¨ stream.read() æ–¹å¼ï¼ˆç±»ä¼¼ Qwenï¼‰"""

    def __init__(self, rate=16000, channels=1, chunk_size=1600):
        self.rate = rate
        self.channels = channels
        self.chunk_size = chunk_size
        self.is_running = False
        self.p = None
        self.stream = None

        # é™éŸ³æ£€æµ‹å‚æ•°
        self.silence_threshold_int16 = int(32768 * SILENCE_THRESHOLD)

    def start(self):
        """å¯åŠ¨éº¦å…‹é£æ•è·"""
        self.p = pyaudio.PyAudio()

        # åˆ—å‡ºå¯ç”¨è®¾å¤‡
        logger.info("=" * 70)
        logger.info("ğŸ¤ å¯ç”¨éŸ³é¢‘è¾“å…¥è®¾å¤‡:")
        logger.info("=" * 70)
        input_devices = []
        for i in range(self.p.get_device_count()):
            info = self.p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:
                input_devices.append(i)
                logger.info(f"  [{i:2d}] {info['name']}")
        logger.info("=" * 70)

        # ä½¿ç”¨é»˜è®¤è¾“å…¥è®¾å¤‡
        try:
            default_device = self.p.get_default_input_device_info()
            device_index = default_device['index']
            logger.info(f"âœ… ä½¿ç”¨é»˜è®¤è®¾å¤‡: [{device_index}] {default_device['name']}")
        except:
            if input_devices:
                device_index = input_devices[0]
                logger.info(f"âœ… ä½¿ç”¨è®¾å¤‡: [{device_index}]")
            else:
                raise RuntimeError("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡")

        # æ‰“å¼€éŸ³é¢‘æµï¼ˆéé˜»å¡æ¨¡å¼ï¼‰
        self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=self.channels,
            rate=self.rate,
            input=True,
            input_device_index=device_index,
            frames_per_buffer=self.chunk_size
        )

        self.is_running = True
        logger.info("=" * 70)
        logger.info(f"âœ… éº¦å…‹é£å·²å¯åŠ¨")
        logger.info(f"   é‡‡æ ·ç‡: {self.rate} Hz")
        logger.info(f"   é€šé“æ•°: {self.channels}")
        logger.info(f"   å—å¤§å°: {self.chunk_size} å­—èŠ‚ ({self.chunk_size * 8 / self.rate * 1000:.0f} ms)")
        logger.info("=" * 70)

    def read_chunk(self):
        """è¯»å–ä¸€ä¸ªéŸ³é¢‘å—ï¼ˆé˜»å¡ï¼‰"""
        if not self.is_running:
            return None

        try:
            audio_data = self.stream.read(self.chunk_size, exception_on_overflow=False)
            rms = audioop.rms(audio_data, 2) / 32768.0  # å½’ä¸€åŒ–åˆ° 0-1

            monitor.record_energy(rms)
            monitor.audio_chunks += 1

            return {
                'data': audio_data,
                'rms': rms,
                'timestamp': time.time()
            }
        except Exception as e:
            logger.error(f"è¯»å–éŸ³é¢‘å¤±è´¥: {e}")
            return None

    def stop(self):
        """åœæ­¢éº¦å…‹é£"""
        self.is_running = False
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        if self.p:
            self.p.terminate()
        logger.info("ğŸ¤ éº¦å…‹é£å·²åœæ­¢")

# ========================================
# å®æ—¶è¯†åˆ«å¼•æ“
# ========================================
class StreamingRecognizer:
    """æµå¼è¯­éŸ³è¯†åˆ«å¼•æ“"""

    def __init__(self, model_name="iic/SenseVoiceSmall"):
        # è¯­è¨€æ˜¾ç¤ºæ˜ å°„
        lang_names = {"zh": "ä¸­æ–‡", "en": "è‹±æ–‡", "ja": "æ—¥è¯­", "ko": "éŸ©è¯­", "yue": "ç²¤è¯­", "auto": "è‡ªåŠ¨è¯†åˆ«"}

        logger.info("=" * 70)
        logger.info("ğŸ”„ æ­£åœ¨åŠ è½½ SenseVoiceSmall æ¨¡å‹...")
        logger.info(f"ğŸŒ è¯­è¨€è®¾ç½®: {lang_names.get(LANGUAGE, LANGUAGE)} ({LANGUAGE})")
        logger.info("=" * 70)

        self.model_name = model_name
        load_start = time.time()

        # æŠ‘åˆ¶æ¨¡å‹åŠ è½½æ—¶çš„ tqdm è¾“å‡º
        with TqdmSuppressor():
            self.model = AutoModel(
                model=model_name,
                vad_model="fsmn-vad",
                vad_kwargs={"max_single_segment_time": 30000},
                device="cpu",
                disable_update=True
            )

        load_time = time.time() - load_start
        logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ (è€—æ—¶: {load_time:.2f} ç§’)")
        logger.info("=" * 70)

        # è¯†åˆ«çŠ¶æ€
        self.sentence_buffer = []  # å½“å‰å¥å­çš„éŸ³é¢‘ç¼“å­˜
        self.committed_text = ""   # å·²æäº¤çš„æ–‡æœ¬
        self.current_text = ""     # å½“å‰æ­£åœ¨è¯†åˆ«çš„æ–‡æœ¬

        # é™éŸ³æ£€æµ‹çŠ¶æ€
        self.silence_duration = 0.0
        self.sentence_duration = 0.0

        # æ€§èƒ½è¿½è¸ª
        self.last_inference_time = 0.0
        self.last_recognition_time = time.time()

    def process_audio_chunk(self, audio_data, rms_energy):
        """
        å¤„ç†éŸ³é¢‘å—ï¼Œè¿”å›è¯†åˆ«ç»“æœ

        Args:
            audio_data: PCM éŸ³é¢‘æ•°æ® (bytes)
            rms_energy: éŸ³é¢‘èƒ½é‡ (å½’ä¸€åŒ– 0-1)

        Returns:
            dict: {
                'text': str,           # å½“å‰è¯†åˆ«çš„æ–‡æœ¬
                'is_final': bool,      # æ˜¯å¦æ˜¯æœ€ç»ˆç»“æœ
                'total_text': str,     # å®Œæ•´æ–‡æœ¬ (å·²æäº¤+å½“å‰)
                'cut_reason': str,     # æ–­å¥åŸå›  (å¦‚æœæ˜¯ final)
                'inference_time': float  # æ¨ç†è€—æ—¶ (ms)
            }
        """
        import re

        # 1. å°†éŸ³é¢‘å—åŠ å…¥ç¼“å­˜
        self.sentence_buffer.append(audio_data)
        chunk_duration = len(audio_data) / 2 / SAMPLE_RATE  # å­—èŠ‚è½¬ç§’
        self.sentence_duration += chunk_duration

        # 2. æ£€æµ‹é™éŸ³
        if rms_energy < SILENCE_THRESHOLD:
            self.silence_duration += chunk_duration
        else:
            self.silence_duration = 0.0

        # 3. åŠ¨æ€è°ƒæ•´æ–­å¥ç­–ç•¥
        dynamic_max_silence = MAX_SILENCE_DURATION
        if self.sentence_duration > 5.0:
            dynamic_max_silence = 0.5
        elif self.sentence_duration > 8.0:
            dynamic_max_silence = 0.3

        # 4. åˆ¤æ–­æ˜¯å¦éœ€è¦è¯†åˆ«
        current_time = time.time()
        time_since_last_inference = current_time - self.last_inference_time

        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ–­å¥
        is_silence_trigger = self.silence_duration > dynamic_max_silence
        is_forced_cut = self.sentence_duration >= MAX_SENTENCE_DURATION

        # å¦‚æœæ—¢ä¸æ˜¯é™éŸ³è§¦å‘ä¹Ÿä¸æ˜¯å¼ºåˆ¶æ–­å¥ï¼Œä¸”è·ç¦»ä¸Šæ¬¡è¯†åˆ«å¤ªè¿‘ï¼Œè·³è¿‡
        should_recognize = (
            is_silence_trigger or
            is_forced_cut or
            time_since_last_inference >= INFERENCE_INTERVAL
        )

        if not should_recognize:
            return None

        # 5. æ‰§è¡Œè¯†åˆ«
        self.last_inference_time = current_time
        inference_start = time.time()

        # åˆå¹¶éŸ³é¢‘æ•°æ®
        combined_audio = b''.join(self.sentence_buffer)

        try:
            # è½¬æ¢ä¸º float32 numpy æ•°ç»„
            audio_np = np.frombuffer(combined_audio, dtype=np.int16).astype(np.float32) / 32768.0

            # æ‰§è¡Œæ¨ç†ï¼ˆæŠ‘åˆ¶ tqdm è¾“å‡ºï¼‰
            with TqdmSuppressor():
                result = self.model.generate(
                    input=audio_np,
                    cache={},
                    language=LANGUAGE,  # ä½¿ç”¨é…ç½®çš„è¯­è¨€
                    use_itn=True,
                    batch_size_s=60
                )

            inference_time = (time.time() - inference_start) * 1000
            monitor.record_inference(inference_time)

            # æå–æ–‡æœ¬
            if result and len(result) > 0:
                raw_text = result[0].get("text", "")
                text = re.sub(r'<\|[^|]+\|>', '', raw_text).strip()

                if text:
                    self.current_text = text

                    # åˆ¤æ–­æ˜¯å¦éœ€è¦æ–­å¥
                    is_punctuation_end = text.endswith(('ã€‚', 'ï¼Ÿ', 'ï¼', '.', '?', '!', 'ï¼Œ', ','))
                    is_long_stable = self.sentence_duration > 2.0 and is_punctuation_end

                    should_commit = (
                        is_silence_trigger or
                        is_forced_cut or
                        is_long_stable
                    )

                    if should_commit:
                        # ç¡®å®šæ–­å¥åŸå› 
                        if is_forced_cut:
                            cut_reason = "force"
                        elif is_long_stable:
                            cut_reason = "punctuation"
                        else:
                            cut_reason = "silence"

                        # æäº¤å¥å­
                        self.committed_text += text
                        monitor.record_sentence_cut(cut_reason, self.sentence_duration)

                        # æ¸…ç©ºç¼“å­˜
                        self.sentence_buffer = []
                        self.silence_duration = 0.0
                        self.sentence_duration = 0.0

                        return {
                            'text': text,
                            'is_final': True,
                            'total_text': self.committed_text,
                            'cut_reason': cut_reason,
                            'inference_time': inference_time
                        }
                    else:
                        # ä¸­é—´ç»“æœ
                        return {
                            'text': text,
                            'is_final': False,
                            'total_text': self.committed_text + text,
                            'inference_time': inference_time
                        }

        except Exception as e:
            logger.error(f"âŒ è¯†åˆ«é”™è¯¯: {e}")
            import traceback
            logger.error(traceback.format_exc())

        return None

# ========================================
# ä¸»ç¨‹åº
# ========================================
def main():
    # è¯­è¨€æ˜¾ç¤ºæ˜ å°„
    lang_names = {"zh": "ä¸­æ–‡", "en": "è‹±æ–‡", "ja": "æ—¥è¯­", "ko": "éŸ©è¯­", "yue": "ç²¤è¯­", "auto": "è‡ªåŠ¨è¯†åˆ«"}
    lang_display = lang_names.get(LANGUAGE, LANGUAGE)

    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     FunASR SenseVoice æœ¬åœ°å®æ—¶è¯†åˆ«æµ‹è¯•                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  é…ç½®:                                                                â•‘
â•‘    â€¢ è¯­è¨€æ¨¡å¼: {lang_display:<6s} ({LANGUAGE})                                          â•‘
â•‘    â€¢ éº¦å…‹é£:   æœ¬åœ°å®æ—¶æ•è·                                           â•‘
â•‘                                                                      â•‘
â•‘  æ“ä½œè¯´æ˜:                                                           â•‘
â•‘    - è¯·å¯¹éº¦å…‹é£è¯´è¯                                                 â•‘
â•‘    - æŒ‰ Ctrl+C åœæ­¢æµ‹è¯•                                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    # å¯åŠ¨éº¦å…‹é£
    mic = MicrophoneCapture(
        rate=SAMPLE_RATE,
        channels=CHANNELS,
        chunk_size=CHUNK_SIZE
    )
    mic.start()

    # åŠ è½½æ¨¡å‹
    recognizer = StreamingRecognizer()

    logger.info("=" * 70)
    logger.info("ğŸ¯ å¼€å§‹å®æ—¶è¯†åˆ«")
    logger.info("=" * 70)

    try:
        while True:
            # ç›´æ¥è¯»å–éŸ³é¢‘å—ï¼ˆé˜»å¡ï¼‰
            audio_item = mic.read_chunk()

            if audio_item is None:
                continue

            # å¤„ç†è¯†åˆ«
            result = recognizer.process_audio_chunk(
                audio_item['data'],
                audio_item['rms']
            )

            if result:
                # è¾“å‡ºç»“æœ
                if result['is_final']:
                    # æœ€ç»ˆç»“æœ - å›ºå®šæ˜¾ç¤º
                    print(f"\râœ… [{result['cut_reason']:10s}] {result['text']}", end='', flush=True)
                    # è®°å½•åˆ°æ—¥å¿—
                    logger.info(
                        f"âœ… [FINAL] æ–­å¥åŸå› : {result['cut_reason']}, "
                        f"æ¨ç†æ—¶é—´: {result['inference_time']:.1f}ms, "
                        f"æ–‡æœ¬: {result['text']}"
                    )
                else:
                    # ä¸­é—´ç»“æœ - å®æ—¶æ›´æ–°
                    print(f"\râ³ [LIVE ] {result['text']:<50s}", end='', flush=True)

    except KeyboardInterrupt:
        logger.info("\n" + "=" * 70)
        logger.info("âš ï¸  æ”¶åˆ°åœæ­¢ä¿¡å·")
    except Exception as e:
        logger.error(f"âŒ é”™è¯¯: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        mic.stop()
        print("\n")
        print(monitor.get_report())
        logger.info(f"ğŸ“ è¯¦ç»†æ—¥å¿—: {log_file}")
        # ç¡®ä¿æ‰€æœ‰æ—¥å¿—å†™å…¥æ–‡ä»¶
        for handler in logging.getLogger().handlers:
            if isinstance(handler, logging.FileHandler):
                handler.flush()
                handler.close()

if __name__ == "__main__":
    main()
